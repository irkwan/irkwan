---
layout:     post
title:      Estimation of Abritary Subset Sum with Priority Sampling
date:       2016-06-02
summary:    Click the title!
categories: tugas
---

# Estimation of abritary subset sum with priority sampling

Suppose we have a stream of object and each stream has a non-negative weight, we want to maintain a generic sample of a certain limited size which can be use to estimate the total weight of arbitary subsets.
Many scheme to solve that problem has a disadvantage at controlling the size of the sample. 
<br>
A good way to solve that problem is use a scheme proposed by Duffield, Lund, and Thorup; called priority sampling.
<br>
_This article is base on Duffield, Lund and Thorup paper "Priority Sampling for Estimation of Arbitary Subset Sums"._

---

## Index

1. [Introduction](#introduction)
2. [Finding a Subset](#finding-a-subset)
3. [Priority Sampling](#priority-sampling)
    1. [Lemma 1](#lemma-1)
    2. [Lemma 2](#lemma-1)
    3. [Lemma 3](#lemma-1)
    4. [Lemma 4](#lemma-1)
4. [References](#references)

---

## Introduction

This article is focusing on sampling from a high volume stream of weighted items. The items arrive faster and in larger quantities than can be saved, so only a sample that can be saved can be stored efficiently. We want to create a generic sample of a certain limitedsize that we can later use to estimate the total weight of arbitrary subsets. 
<br><br>
Applied to internet traffic analysis, the items could be record summarizing the flows of packets streaming by a router, with say, a hundred records to be sampled each hour. A subset could be flow records of a worm attack whose signature is only determined after sampling has taken place. The samples taken in the past allow us to trace the history of the attack even though the worm was unknown at the time of sampling.

## Finding a Subset

The point for selecting subsets is that an item besides the weight has any associated information, and selecting an item may be based with the associated information. 
<br><br>
**Internet trafic analysis**
<br>
Internet routers transfer information about transmition of data that pass through. This transmission is called flows which could be a ftp transfer, email, or some other related data. A flow record is exported with statistics such as summary information which contain application type, source and destination IP addresses, and the number of packets and total bytes in the flow. Now, we can choose the byte size as the weight.
<br>
We might want to sample the flows such that we can aswer _like how many bytes of traffic came from a given customer or how much traffic was generated by a certain application_. If we knew which selection in advance of measurement were of interest, we could have a counter for each selection and increment these as flows passed by. The challange for that question is we must not be constraint to selection known in advance of measurement.
<br><br>
**External information in the selection**
<br>
Supposed a department store sample of all their sales which include information such as item, date, time, and price. Based on the sample we might as a question _How many days of rain before we get a boom in the sale of rain gear?_. The asnwer is we can find a database with historical rain information and then looked up at each sample sales record with rain gear, and check how many days it had rained before the sale. From this example, we can concluded that the selection can be based on external information that not even imagined relevant at the time when measurements are made.

## Priority Sampling

Suppose we are give n items with weight w. The goal is to compute all the subset sum queries. In some situations, when n is huge, we can't really store all the weights from the item. The way to compute that is take a sample from the universe and then calculated the weight of the sample. 
<br><br>
There's many techniques to take a sample; from *randomly picked up sample* - missed item with high weight to *weighted sample* - always give high weight items. Each of the schemes show a vulnarablity but there is an elegant scheme proposed by Duffield, Lund, and Thorup which called priority sampling.
<br><br>

> ![Image1](https://cloud.githubusercontent.com/assets/19385651/15768064/eb34e382-2977-11e6-8b96-3db0ea1d6be4.PNG)

<br>

> Image1. Priority sampling of size 3 from a set of 10 weighted item

<br>
The priority sampling scheme as can seen bellow :

* For each item, generate a random number a<sub>i</sub> between 0 and 1. Assign a priority  <sub>i</sub> to i of value w<sub>i</sub>/a<sub>i</sub> where q<sub>i</sub> is unique from others.
* S is the set of items with the k highest prorities.
* Take the top k elements (with respect to priority), and let the priority of the (k+1)<sup>th</sup> element be t. If k >= n set t = 0.
* If i is subset of S, set w<sup>'</sup><sub>i</sub> = max(w<sub>i</sub>, t), else set w<sup>'</sup><sub>i</sub> = 0.

### Lemma 1

![lemma1](https://raw.githubusercontent.com/MalvinJu/MalvinJu.github.io/MalvinJu-patch-1/lemma1.PNG)

### Lemma 2

![lemma2](https://cloud.githubusercontent.com/assets/19385651/15768093/34c870c2-2978-11e6-8965-9600eafec073.PNG)

### Lemma 3

![lemma3](https://cloud.githubusercontent.com/assets/19385651/15768098/3c499ef2-2978-11e6-8dfe-acba7f559121.PNG)

### Lemma 4

![lemma4](https://cloud.githubusercontent.com/assets/19385651/15768099/45504758-2978-11e6-912d-60b346be6870.PNG)

## References

* Nick Duffield, Carsten Lund, and Mikkel Thorup. Priority sampling for estimation of arbitrary subset sums. Journal of the ACM (JACM), 2007.
